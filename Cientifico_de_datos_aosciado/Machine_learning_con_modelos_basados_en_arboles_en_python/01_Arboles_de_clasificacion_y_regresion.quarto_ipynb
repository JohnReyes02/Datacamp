{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Árboles de clasificación y regresión\"\n",
        "author: \"Edwin John Fredy Reyes Aguirre\"\n",
        "date: today\n",
        "toc: true\n",
        "toc-title: \"Contenido\"\n",
        "---\n",
        "\n",
        "\n",
        "Los Árboles de clasificación y regresión (CART) son un conjunto de modelos de aprendizaje supervisado que se utilizan para problemas de clasificación y regresión. En este capítulo, conocerás el algoritmo CART.\n",
        "\n",
        "## Árbol de decisión para la clasificación\n",
        "\n",
        "-   Árbol de calsificación\n",
        "\n",
        "    -   Secuencia de preguntas si - no acerca de caracteristicas (features) individuales.\n",
        "    -   Objetivo: Inferir las etiquetas.\n",
        "    -   Pueden capturar relaciones no lineales entre entidades y etiquetas.\n",
        "    -   No requieren que las características estén en la misma escala. (Ej: Estandarización).\n",
        "\n",
        "-   Dataset Cáncer de mama en 2D\n",
        "\n",
        "    ![](images/paste-2.png){width=\"450\"}\n",
        "\n",
        "-   Diagrama de árbol de decisión\n",
        "\n",
        "    -   El número máximo de ramas que separan la parte superior de un extremo, se conoce como, profundidad máxima\n",
        "\n",
        "        ![](images/paste-3.png){width=\"450\"}\n",
        "\n",
        "-   Árbol de clasificación en scikit-learn\n"
      ],
      "id": "81c9867b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# | eval: false\n",
        "# Importe DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Importe train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importe accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Divida el dataset en 80% entrenamiento, 20% prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=1)\n",
        "\n",
        "# Instancie dt\n",
        "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
        "\n",
        "# Fit dt al set de entrenamiento\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Prediga con el set de prueba las etiquetas\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Evalue la exactitud del set de prueba\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "id": "a89edbe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Regiones de Decisión\n",
        "\n",
        "    Un modelo de clasificación divide el espacio de características en regiones donde todas las instancias en una región se asignan a una sola etiqueta de clase.\n",
        "\n",
        "    Límites de Decisión: Superficie que separa diferentes regiones de decisión.\n",
        "\n",
        "    ![](images/paste-4.png){width=\"450\"}\n",
        "\n",
        "### Entrena tu primer árbol de clasificación\n",
        "\n",
        "En este ejercicio trabajarás con el Conjunto de datos de cáncer de mama de Wisconsin del repositorio de machine learning UCI. Predecirás si un tumor es maligno o benigno basándote en dos características: el radio medio del tumor (`radius_mean`) y su número medio de puntos cóncavos (`concave points_mean`).\n",
        "\n",
        "El conjunto de datos ya está cargado en tu espacio de trabajo y está dividido en un 80 % de entrenamiento y un 20 % de prueba. Las matrices de características se asignan a X_train y X_test, mientras que las matrices de etiquetas se asignan a y_train y y_test, donde la clase 1 corresponde a un tumor maligno y la clase 0 a un tumor benigno. Para obtener resultados reproducibles, también definimos una variable llamada `SEED` que se fija en 1.\n"
      ],
      "id": "fb863b27"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "wbc = pd.read_csv('./data/wbc.csv')\n",
        "wbc.head()"
      ],
      "id": "a9675036",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Separamos las columnas que corresponden a X\n",
        "X = wbc[['radius_mean', 'concave points_mean']] \n",
        "\n",
        "# Separamos la columna con los datos a predecir\n",
        "y = wbc['diagnosis']\n",
        "y = y.map({'M': 1, 'B': 0})\n",
        "\n",
        "SEED = 1"
      ],
      "id": "fd0773d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=SEED)"
      ],
      "id": "291d5312",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instrucciones:\n",
        "\n",
        "-   Importa `DecisionTreeClassifier` desde `sklearn.tree`.\n",
        "\n",
        "-   Instancia un `DecisionTreeClassifier` `dt` de profundidad máxima igual 6.\n",
        "\n",
        "-   Ajusta `dt` al conjunto de entrenamiento.\n",
        "\n",
        "-   Predice las etiquetas del conjunto de pruebas y asigna el resultado a `y_pred`.\n"
      ],
      "id": "d2527e2b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import DecissionTreeClassifier from sklearn.from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
        "dt = DecisionTreeClassifier(max_depth=6, random_state=SEED)\n",
        "\n",
        "# Fit dt to the training set\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = dt.predict(X_test)\n",
        "print(y_pred[0:5])"
      ],
      "id": "1acb126c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede ver las primeras cinco predicciones hechas por el árbol ajustado en el conjunto de prueba.\n",
        "\n",
        "### Evaluar el árbol de clasificación\n",
        "\n",
        "Ahora que has ajustado tu primer árbol de clasificación, es hora de evaluar su rendimiento en el conjunto de pruebas. Lo harás utilizando la métrica de precisión, que corresponde a la fracción de predicciones correctas realizadas en el conjunto de pruebas.\n",
        "\n",
        "#### Instrucciones\n",
        "\n",
        "-   Importa la función `accuracy_score` de `sklearn.metrics`.\n",
        "\n",
        "-   Predice las etiquetas del conjunto de pruebas y asigna la matriz obtenida a `y_pred`.\n",
        "\n",
        "-   Evalúa la puntuación de precisión del conjunto de pruebas de `dt` llamado `accuracy_score()` y asigna el valor a `acc`.\n"
      ],
      "id": "e2045caf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute test set accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Test set accuracy: {acc:.2f}')"
      ],
      "id": "8ed7a485",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regresión logística frente a árbol de clasificación\n",
        "\n",
        "Un árbol de clasificación divide el espacio de características en **regiones rectangulares**. En cambio, un modelo lineal como la regresión logística solo produce un único límite de decisión lineal que divide el espacio de características en dos regiones de decisión.\n",
        "\n",
        "Hemos escrito una función personalizada llamada `plot_labeled_decision_regions()` que puedes utilizar para trazar las regiones de decisión de una lista que contenga dos clasificadores entrenados.\n"
      ],
      "id": "eab1acf0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "def plot_labeled_decision_regions(X, y, models):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    if len(models) != 2:\n",
        "        raise Exception('''\n",
        "        Models should be a list containing only two trained classifiers.\n",
        "        ''')\n",
        "    if not isinstance(X, pd.DataFrame):\n",
        "        raise Exception('''\n",
        "        X has to be a pandas DataGrame with two numerical features.\n",
        "        ''')\n",
        "    if not isinstance(y, pd.Series):\n",
        "        raise Exception('''\n",
        "        y has to be a pandas Series corresponding to the labels.\n",
        "        ''')\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(6.0, 2.7), sharey=True)\n",
        "    for i, model in enumerate(models):\n",
        "        plot_decision_regions(X.values, y.values, model, legend= 2, ax = ax[i])\n",
        "        ax[i].set_title(model.__class__.__name__)\n",
        "        ax[i].set_xlabel(X.columns[0])\n",
        "        if i == 0:\n",
        "            ax[i].set_ylabel(X.columns[1])\n",
        "        ax[i].set_ylim(X.values[:,1].min(), X.values[:,1].max())\n",
        "        ax[i].set_xlim(X.values[:,0].min(), X.values[:,0].max())\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "c3d59222",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instrucciones:\n",
        "\n",
        "-   Importa `LogisticRegression` desde `sklearn.linear_model`.\n",
        "\n",
        "-   Instancia un modelo `LogisticRegression` y asígnalo a `logreg`\n"
      ],
      "id": "4ba18535"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import LogisticRegression from sklearn.linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instatiate logreg\n",
        "logreg = LogisticRegression(random_state=1)\n",
        "\n",
        "# Fit logreg to the training set\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Define a list called clfs containing the two classifiers logreg and dt\n",
        "clfs = [logreg, dt]\n",
        "\n",
        "# Review the decision regions if the two classifiers\n",
        "plot_labeled_decision_regions(X_test, y_test, clfs)\n",
        "plt.show()"
      ],
      "id": "96fd5e9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aprendizaje del árbol de clasificación\n",
        "\n",
        "-   Construyendo los bloques de un árbol de decisión\n",
        "\n",
        "    -   Árboles de decisión: Estructura de datos que consiste de una jerarquía de nodos.\n",
        "\n",
        "    -   Nodo: Punto que implica una pregunta o una predicción.\n",
        "\n",
        "    -   Hay tres clases de nodos:\n",
        "\n",
        "        -   **Root**: Es el nodo en el que el árbol de decisiones empieza a crecer. No tiene nodo padre, involucra una pregunta que da lugar a dos nodos hijos a través de dos ramas.\n",
        "\n",
        "        -   **Internal node**: Es un nodo que tiene un nodo padre. También implica una pregunta que da lugar a 2 nodos hijos\n",
        "\n",
        "        -   **Leaf**: Tiene un nodo padre y no tiene hijos. Tiene un nodo principal y no implica preguntas. Es donde se hace la predicción.\n",
        "\n",
        "-   Ganancia de Información (IG)\n",
        "\n",
        "    ![](images/paste-5.png){width=\"500\"}\n",
        "\n",
        "    $$ IG(\\underbrace{f}_{\\text{feature}}, \\underbrace{sp}_{\\text{split-point}} ) = I(\\text{parent}) - \\big( \\frac{N_{\\text{left}}}{N}I(\\text{left}) + \\frac{N_{\\text{right}}}{N}I(\\text{right})  \\big) $$\n",
        "\n",
        "    -   Criterios para medir la impureza de un nodo\n",
        "\n",
        "        -   Índice de gini\n",
        "        -   entropía\n",
        "\n",
        "-   Aprendizaje de un árbol de clasificación\n",
        "\n",
        "    -   Los nodos crecen recursivamente.\n",
        "    -   En cada nodo, la división de los datos se basa en:\n",
        "        -   Caracterísitca $f$ y el punto de división $sp$ para maximizar $IG(\\text{node})$.\n",
        "    -   Si $IG(\\text{node}) = 0$, el nodo se declara como hoja.\n",
        "\n",
        "### Hacer crecer un árbol de clasificación\n",
        "\n",
        "Cuál de las siguientes no es una regla de crecimiento de un árbol de calsificación sin restricciones?\n",
        "\n",
        "**Respuestas Posibles**\n",
        "\n",
        "-   [ ] La existencia de un nodo depende del estado de sus predecesores.\n",
        "-   [ ] La impureza de un nodo puede determinarse utilizando distintos criterios, como la entropía y el índice de Gini.\n",
        "-   [ ] Cuando la ganancia de información resultante de dividir un nodo es nula, el nodo se declara hoja.\n",
        "-   [x] Cuando se divide un nodo interno, la división se realiza de forma que se minimice la gannacia de información.\n",
        "\n",
        "### Utilizar la entropía como criterio\n",
        "\n",
        "En este ejercicio, entrenarás un árbol de clasifiacación en el conjunto de datos Cáncer de Mama de Wisconsin utilizando la entropia como criterio de información. Lo harás utilizando las 30 características del conjunto de datos, que se divide en un 80% de entrenamiento y un 20 % de prueba.\n",
        "\n",
        "#### Instrucciones:\n",
        "\n",
        "-   Importa `DecisionTreeClassifier` desde `sklearn.tree`.\n",
        "-   Instancia un `DecisionTreeClassifier` `dt_entropy` con una profundidad máxima de 8.\n",
        "-   Establece el criterio de información en `entropy`.\n",
        "-   Ajusta `dt_entropy` en el conjunto de entrenamiento.\n"
      ],
      "id": "423daa72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import DesicionTreeClassifier from sklearn.ree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instatntiate dt_entropy, set 'entropy' as the information criterion\n",
        "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
        "\n",
        "# Fit dt_entropy to the training set\n",
        "dt_entropy.fit(X_train, y_train)"
      ],
      "id": "4af8db43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entropía vs índice de Gini\n",
        "\n",
        "En este ejercicio compararás la precisión del conjunto de pruebas de `dt_entropy` con la precisión de otro árbol llamado `dt_gini`. El árbol `dt_gini` se entrenón en el mismo conjunto de datos utilizando los mismos parámetros, excepto el criterio de información, que se fijo en el índice de Gini utilizando la palabra clave `gini`\n"
      ],
      "id": "92e4922b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n",
        "dt_gini.fit(X_train, y_train)"
      ],
      "id": "350e94b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instrucciones:\n",
        "\n",
        "-   Importa `accuracy_score` desde `sklearn.metrics`.\n",
        "-   Predice las etiquetas del conjunto de prueba de `dt_entropy` y asigna el resultado a `y_pred`.\n",
        "-   Evalúa la precisión del conjunto de pruebas de `dt_entropy` y asigna el resultado a `accuracy_entropy`.\n",
        "-   Revisa `accuracy_entropy` y `accuracy_gini`.\n"
      ],
      "id": "0373b843"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import accuracy_score form sklearn.metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Use dt_entropy to predict test set labels\n",
        "y_pred = dt_entropy.predict(X_test)\n",
        "y_pred_gini = dt_gini.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate accuracy_entropy\n",
        "accuracy_entropy = accuracy_score(y_test, y_pred)\n",
        "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
        "\n",
        "# Print accuracy_entropy\n",
        "print(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')\n",
        "\n",
        "# Print accuracy_gini\n",
        "print(f'Accuracy achieved by using gini: {accuracy_gini:.3f}')"
      ],
      "id": "b89ab39c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los dos modelos logran casi la misma precisión. La mayoría de las veces, el índice de gini y la entropía llevan a los mismos resultados. El índice de gini es ligeramente más rápido de calcular y es el criterio predeterminado utilizado en el modelo `DecisionTreeClassifier` de scikit-learn.\n",
        "\n",
        "## Árbol de decisión para la regresión\n",
        "\n",
        "-   Árbol de regresión en scikit-learn\n"
      ],
      "id": "44543c91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# | eval: false\n",
        "# Import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import mean_squared_error as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Split data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=3)\n",
        "\n",
        "# Instantiate a DecisionTreeRegressor 'dt'\n",
        "dt = DecisionTreeRegressor(max_depth=4,\n",
        "                           min_samples_leaf=0.1,\n",
        "                           random_state=3)  # dato de parada con 10% datos por hoja\n",
        "\n",
        "# Fit 'dt' to the training-set\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict test-set labels\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute test-set MSE\n",
        "mse_dt = MSE(y_test, y_pred)\n",
        "\n",
        "# Compute test_set RMSE\n",
        "rmse_dt = mse_dt ** (1 / 2)\n",
        "\n",
        "# Print rmse_dt\n",
        "print(rmse_dt)"
      ],
      "id": "100d0398",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Criterio de información para el Árbol de Regresión $$ I(\\text{node}) = \\underbrace{\\text{MSE}(\\text{node})}_{\\text{mean-squared-error}} = \\dfrac{1}{N_{\\text{node}}} \\sum_{i \\in \\text{node}} \\big(y^{(i)} - \\hat{y}_{\\text{node}}  \\big)^2 $$ $$ \\underbrace{\\hat{y}_{\\text{node}}}_{\\text{mean-target-value}} = \\dfrac{1}{N_{\\text{node}}} \\sum_{i \\in \\text{node}}y^{(i)}$$\n",
        "\n",
        "-   Prediction $$ \\hat{y}_{\\text{pred}}(\\text{leaf}) = \\dfrac{1}{N_{\\text{leaf}}} \\sum_{i \\in \\text{leaf}} y^{(i)}$$\n",
        "\n",
        "-   Regresión lineal vs Árbol de regresión\n",
        "\n",
        "    ![](images/paste-6.png){width=\"590\"}\n",
        "\n",
        "\n",
        "### Entrena tu primer árbol de regresión \n",
        "\n",
        "En este ejercicio, entrenarás un árbol de regresión para predecir el consumo de `mpg` (millas por galón) de los coches del conjunto de datos auto-mpg utilizando las seis características disponibles.\n",
        "\n",
        "\n",
        "Leemos el dataset:"
      ],
      "id": "1269b3e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "auto = pd.read_csv('./data/auto.csv')\n",
        "auto.head()"
      ],
      "id": "e6307f5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se realiza una conversión de variables"
      ],
      "id": "ec8bb3de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "auto = pd.get_dummies(auto, dtype=int) # columnas categoricas a numericas\n",
        "auto.head()"
      ],
      "id": "49d6b1fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = auto.drop('mpg', axis='columns')\n",
        "y = auto['mpg']"
      ],
      "id": "980ddea2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
      ],
      "id": "f21aa8ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instrucciones\n",
        "\n",
        "- Importa `DecisionTreeRegressor` desde `sklearn.tree`.\n",
        "- Instancia un `DecisionTreeRegressor` `dt` con profundidad máxima 8 y `min_samples_leaf` fijado en 0.13.\n",
        "- Ajusta `dt` al conjunto de entrenamiento\n"
      ],
      "id": "4573140b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import DecisionTreeRegressor from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)\n",
        "\n",
        "# Fit dt to the training set\n",
        "dt.fit(X_train, y_train)"
      ],
      "id": "bb4906e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluar el árbol de regresión\n",
        "\n",
        "En este ejercicio, evaluarás el rendimiento del conjunto de pruebas de `dt` utilizando la métrica Error cuadrático medio (RMSE). La RMSE de un modelo mide, por término medio, cuánto difieren las predicciones del modelo de las etiquetas reales. El RMSE de un modelo puede obtenerse calculando la raíz cuadrada del Error Cuadrático Medio del modelo (MSE).\n",
        "\n",
        "#### Instrucciones:\n",
        "\n",
        "- Importa la función `mean_squared_error` como `MSE` desde `sklearn.metrics`.\n",
        "- Predice las etiquetas del conjunto de pruebas y asigna la salida a `y_pred`.\n",
        "- Calcula el conjunto de pruebas MSE llamando a `MSE` y asigna el resultado a `mse_dt`.\n",
        "- Calcula el conjunto de prueba RMSE y asígnalo a `rmse_dt`  \n"
      ],
      "id": "b68700d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import mean_squared_error from sklearn.metrics as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Compute y_pred\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute mse_dt\n",
        "mse_dt = MSE(y_test, y_pred)\n",
        "\n",
        "# Compute rmse_dt\n",
        "rmse_dt = (mse_dt) ** (1 / 2)\n",
        "\n",
        "# Print rmse_dt\n",
        "print(f'Test set RMSE of dt: {rmse_dt:.2f}')"
      ],
      "id": "d2e966ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regresión lineal vs árbol de regresión\n",
        "\n",
        "En este ejercicio, compararás el conjunto de pruebas RMSE de `dt` con el obtenido por un modelo de regresión lineal. Ya hemos instanciado un modelo de regresión lineal `lr` y lo hemos entrenado con el mismo conjunto de datos que `dt`\n",
        "\n",
        "Preprocesamiento:\n"
      ],
      "id": "f7d9c362"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "lr.fit(X_train, y_train)"
      ],
      "id": "04164904",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instrucciones\n",
        "\n",
        "- Predice las etiquetas del conjunto de pruebas utilizando el modelo de regresion lineal (`lr`) y asigna el resulta a `y_pred_lr`.\n",
        "- Calcula el conjunto de pruebas MSE y asigna el resultado a `mse_lr`.\n",
        "- Calcula el conjunto de prueba RMSE y asigna el resultado a `rmse_lr`\n"
      ],
      "id": "0f57e1cf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict test set labels\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Compute mse_lr\n",
        "mse_lr = MSE(y_pred_lr, y_test)\n",
        "\n",
        "# Compute rmse_lr\n",
        "rmse_lr = mse_lr ** (1/2)\n",
        "\n",
        "# print rmse_lr\n",
        "print(f'Linear Regression test set RMSE: {rmse_lr:.2f}')\n",
        "\n",
        "# print rmse_dt\n",
        "print(f'Regression Tree test set RMSE: {rmse_dt:.2f}')"
      ],
      "id": "bdd7ea10",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "venv",
      "language": "python",
      "display_name": "Python (venv)",
      "path": "/Users/edwinmacmini/Library/Jupyter/kernels/venv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}