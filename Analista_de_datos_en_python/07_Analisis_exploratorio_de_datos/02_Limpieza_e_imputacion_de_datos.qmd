# Limpieza e imputación de datos

Explorar y analizar datos a menudo significa tratar con valores perdidos, tipos de datos incorrectos y valores atípicos. En este capítulo, aprenderás técnicas para gestionar estos problemas y agilizar tus procesos en EDA.

## Tratar los datos que faltan

-   Por qué un dato faltante es un problema?

    -   Afectan las distribuciones
    -   Los datos de la población son menos repreesntativos
    -   Puede resultar en conclusiones incorrectas

-   Ejemplo datos de profesionales de datos

| Column | Description | Data type |
|--------------------|---------------------------------|-------------------|
| `Working_Year` | Year the data was obtained | Float |
| `Designation` | Job title | String |
| `Experience` | Experience level e.g., `"Mid"`, `"Senior"` | String |
| `Employment_Satus` | Type of employment contract e.g., `"FT"`, `"PT"` | String |
| `Employee_Location` | Country of employment | String |
| `Company_Size` | Labels for company size e.g., `"S"`, `"M"`, `"L"` | String |
| `Remote_Working_Ratio` | Porcentage of time working remotely | Integer |
| `Salary_USD` | Salary in US dollars | Float |

-   Revisando los datos faltantes

```{python}
#| echo: true
#| eval: false
print(salaries.isna().sum())
```

![](images/paste-22.png)

-   Estrategias para el manejo de datos faltantes

    -   Eliminar los datos faltantes

        -   5 % o menos del total de valores

    -   Imputar la media, mediana o la moda

        -   Depende de la distribución y contexto

    -   Imputar por sub-grupos

        -   Diferentes niveles de experiencia tienen diferente mediana en el salario

-   Eliminando valores faltantes

```{python}
#| echo: true
#| eval: false
threshold = len(salaries) * 0.05
print(threhold)
```

![](images/paste-23.png)

```{python}
# | echo: true
# | eval: false
cols_to_drop = salaries.columns[salaries.isna().sum() <= threshold]
print(cols_to_drop)
```

![](images/paste-24.png)

```{python}
#| echo: true
#| eval: false
salaries.dropna(subset=cols_to_drop, inplace=True) # Para actualizar el DataFrame
```

-   Imputando una estadística de resumen

```{python}
#| echo: true
#| eval: false
cols_with_missing_values = salaries.columns[salaries.isna().sum() > 0]
print(cols_with_missing_values)
```

![](images/paste-25.png)

```{python}
#| echo: true
#| eval: false
    for col in cols_with_missing_values[:-1]:
        salaries[col].fillna(salaries[col].mode()[0])
```

-   Revisando los valores faltantes que faltan

```{python}
#| echo: true
#| eval: false
print(salaries.isna().sum())
```

![](images/paste-26.png)

-   Imputando por subgrupo

```{python}
#| echo: true
#| eval: false
salaries_dict = salaries.groupby('Experience')['Salary_USD'].median().to_dict()
print(salaries_dict)
```

![](images/paste-27.png)

```{python}
#| echo: true
#| eval: false
salaries['Salary_USD'] = salaries['Salary_USD'].fillna(salaries['Experience'].map(salaries_dict))
```

![](images/paste-28.png)

### Tratar los datos que faltan

Es importante tratar los datos que faltan antes de empezar el análisis.

Un enfoque consiste en descartar los valores que faltan si representan una pequeña proporción, normalmente el 5 %, de los datos.

Trabajando con un conjunto de datos sobre precios de tiquetes de avión, almacenado como un DataFrame de pandas llamado `planes`, tendrás que contar el número de valores perdidos en todas las columnas, calcular el cinco porciento de todos los valores, utilizar este umbral para eliminar observaciones y comprobar cuántos valores perdidos quedan en el conjunto de datos.

```{python}
import pandas as pd

ruta = './data/planes.csv'
planes = pd.read_csv(ruta)
print(planes.head)
```

#### Instrucciones

1.  Imprime el número de valores perdidos en cada columna del DataFrame

```{python}
# Count the number of missing values in each column
print(planes.isna().sum())
```

2.  Calcula a cuántas observaciones equivale el cinco porciento del DataFrame `planes`

```{python}
# Find the five percent threshold
threshold = len(planes) * 0.05
print(threshold)
```

3.  

-   Crea `cols_to_drop` aplicando una indexación booleana a las columnas del DataFrame con valores perdidos menores o iguales que el umbral.

-   Utiliza este filtro para eliminar los valores que faltan y guardar el DataFrame actualizado.

```{python}
# Create a filter
cols_to_drop = planes.columns[planes.isna().sum() <= threshold]
print(cols_to_drop)

# Drop missing values for columns below the threshold
planes.dropna(subset=cols_to_drop, inplace=True)

print(planes.isna().sum())
```

Al crear un umbral de valores faltantes y usarlo para filtrar columnas, haz logrado eliminar los valores faltantes de todas las columnas excepto `"Additinal_Info"` y `"Price"`.

### Estrategias para datos que faltan

La regla del cinco porciento ha funcionado muy bien en tu conjunto de dato `planes`, ¡eliminando los valores perdidos de nueve de las 11 columnas!

Ahora tienes que decidir qué hacer con las columnas `"Additional_Info"` y `"Price"`, a las que les faltan los valores `300` y `368` respectivamente.

Primero echarás un vistazo a lo que contiene `"Additional_Info"`, y después visualizarás el precio de los billetes de avión de distintas compañías aéreas.

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
```

#### Instrucciones

1.  Imprime los valores y frecuencias de `"Additional_Info"`.

```{python}
# Check the values of the Additional_Info column
print(planes['Additional_Info'].value_counts())
```

2.  Crea un boxplot de `"Price"` frente a `"Airline"`

```{python}
# Create a box plot of Price by Airline
sns.boxplot(data=planes, x='Airline', y='Price',
            hue='Airline', legend=False)

plt.show()
```

3.  **Pregunta**

-   ¿Cómo debes tratar los valores que faltan en `"Additional_Info"` y `"Price"`.?

**Respuestas Posibles**

-   [ ] Elimina la columna `"Additional_Info"` e imputa la media para los valores que faltan de `"Price"`.
-   [ ] Elimina los valores de `"No info"` de `"Additiona_Info"` e imputa la mediana de los valores que faltan de `"Price"`.
-   [ ] Elimina la columna `"Additional_Info"` e imputa la media por `"Airline"` para los valores que falten de `"Price"`.
-   [x] Elimina la columna `"Additional_Info"` e imputa la mediana por `"Airline"` para los valores que falten de `"Price"`.

No necesitamos la columna `"Additional_Info"`, y deberías imputar la mediana de `"Price"` por `"Airline"` para representar los datos con precisión.

### Imputar los precios de los aviones que faltan

!Ahora solo queda una columna con valores perdidos!

Has eliminado la columna `"Additional_Info"` de `planes`, el último paso es imputar los datos que faltan en la columna `"Price"` del conjunto de datos.

Como recordatorio, tú generaste este diagrama de caja, que sugería que imputar el precio medio basándose en el `"Airline"` ¡es un enfoque sólido!

```{python}
# Eliminamos la columna Additional_Info
planes = planes.drop('Additional_Info', axis=1)
planes.columns
```

#### Instrucciones

1.  Agrupa `planes` por aerolínea y calcula el precio medio.

```{python}
# Calculate median plane ticket prices by Airplane
airline_prices = planes.groupby('Airline')['Price'].median()

print(airline_prices)
```

2.  Convierte los precios medios agrupados en un diccionario.

```{python}
# Convert to a dictionary
prices_dict = airline_prices.to_dict()
print(prices_dict)
```

3.  

-   Imputa condicionalmente los valores perdidos de `"Price"` asignando los valores de la columna `"Airline"` en función de `prices_dict`

-   Comprueba si faltan valores

```{python}
# Map the dictionary to missing values of Price by Airline
planes['Price'] = planes['Price'].fillna(planes['Airline'].map(prices_dict))

# Check for missing values
print(planes.isna().sum())
```

Convertiste un DataFrame agrupado a un diccionario y luego lo usaste para llenar condicionalmente los valores faltantes de `"Price"` basándote en `"Airline"`. Ahora vamos a explorar cómo realizar análisis exploratorio en datos categóricos.

## Convertir y analizar datos categóricos

-   Previsualizar los datos

```{python}
#| echo: true
#| eval: false
print(salaries.select_dtypes('object').head())
```

![](images/paste-29.png)

-   Títulos de los trabajos

```{python}
#| echo: true
#| eval: false
print(salaries['Designation'].value_counts())
```

![](images/paste-30.png)

```{python}
# | echo: true
# | eval: false
print(salaries['Designation'].nunique())
```

![](images/paste-31.png)

![](images/paste-32.png)

-   Extrayendo valores desde las categorías

    -   El formato actual de los datos limita la capacidad de generar información.

    -   `pandas.Series.str.contains()`

        -   Busca en una columna una cadena especifica o múltiples cadenas.

```{python}
#| echo: true
#| eval: false
salaries['Designation'].str.contains('Scientist')
```

![](images/paste-33.png)

-   Filtrar filas que contienen una o más frases

    -   Palabras de interes: Machine Learning o AI

```{python}
#| echo: true
#| eval: false
salaries['Designation'].str.contains('Machine Learning|AI')
```

![](images/paste-34.png)

-   Buscar múltiples frases en una cadena de caracteres

    -   Palabras de interes: Cualquiera que inicie con Data

```{python}
# | echo: true
# | eval: false
salaries['Designation'].str.contains('ˆData')
```

![](images/paste-35.png)

Ahora que se tiene una idea de cómo funciona este método, definamos una lista de títulos de trabajo que queremos encontrar:

```{python}
#| echo: true
#| eval: false
job_categories = ['Data Science', 'Data Analytics',
                   'Data Engineering', 'Machine Learning',
                   'Managerial', 'Consultant']
```

Luego necesitamos crear variables que contengan nuestros filtros

```{python}
#| echo: true
#| eval: false
data_science = 'Data Scientist|NLP'
data_analyst = 'Analyst|Analytics'
data_engineer = 'Data Engineer|ETL|Architect|Infrastructure'
ml_engineer = 'Machine Learning|ML|Bid Data|AI'
manager = 'Manager|Head|Director|Lead|Principal|Staff'
consultant = 'Consultant|Freelance'
```

El siguiente paso es crear una lista con nuestro rango de condiciones para el método `str.contains`

```{python}
#| echo: true
#| eval: false
conditions = [
    (salaries['Designation'].str.contains(data_science)),
    (salaries['Designation'].str.contains(data_analyst)),
    (salaries['Designation'].str.contains(data_engineer)),
    (salaries['Designation'].str.contains(ml_engineer)),
    (salaries['Designation'].str.contains(manager)),
    (salaries['Designation'].str.contains(consultant))
]
```

Finalmente, podemos crear nuestra nueva columna `Job_Category` usando la función de selección de Numpy

```{python}
#| echo: true
#| eval: false
salaries['Job_Category'] = np.select(conditions,
                                     job_categories,
                                     default='Other')
```

Al obtener una vista previa de la Designación y nuestra nueva columna Job_Category, podemos verificar los primeros cinco valores.

```{python}
#| echo: true
#| eval: false
print(salaries[['Designation', 'Job_Category']].head())
```

![](images/paste-36.png)

-   Visualización de la frecuencia de la categoría job

```{python}
#| echo: true
#| eval: false
sns.countplot(data=salaries, x='Job_Category')
plt.show()
```

![](images/paste-37.png)

### Encontrar el número de valores únicos

Te gustaría practicar algunas de las habilidades de manipulación y análisis de datos categóricos que acabas de ver. Para ayudarte a identificar qué datos podrían reformatearse para extraer valor, vas a averiguar qué columnas no numéricas del conjunto de datos `planes` tienen un gran número de valores únicos.

#### Instrucciones

-   Filtra `planes` para las columnas que sean del tipo datos `"object"`.

-   Recorre las columnas del conjunto de datos.

-   Añade el iterador de columna a la sentencia print y, a continucación, llama a la función para que devuelva el número de valores únicos de la columna.

```{python}
# Filter the DataFrame for objects columns
non_numeric = planes.select_dtypes('object')

# Loop through columns
for column in non_numeric.columns:
    # Print the number of unique values
    print(f"Number of unique values in {column} column: {non_numeric[column].nunique()}")
```

Curiosamente, `"Duration"` es actualmente una columna de tipo objeto cuando debería ser una columna numérica, ¡y tiene 362 valores únicos! Vamos a averiguar más sobre esta columna.

### Categoría de duración de vuelos

Como has visto, hay 362 valores únicos en la columna `"Duration"` de `planes`. Llamando a `planes['Duration'].head()`, vemos los siguientes valores.

```{python}
#| echo: false
planes['Duration'].head()
```

Parece que no será sencillo convertirlo a números. Sin embargo, ¡podrías clasificar los vuelos por duración y examinar la frecuencia de las distintas longitudes de vuelo!

Crearás una columna `"Duration_Category"` en el DataFrame `planes`. Antes tendrás que crear una lista de valores que deseas insertar en el DataFrame, seguida de los valores existentes a partir de los cuales deben crearse.

#### Instrucciones

1.  Crea una lista de categorías que contengan `"Short-haul"`, `"Medium"` y `"Long-haul"`.

```{python}
# Create a list of categories
flight_categories = ['Short-haul', 'Medium', 'Long-haul']
```

2.  

-   Crea `short_flights`, una cadena para capturar valores de `"0h"`, `"1h"`, `"2h"`, `"3h"`, `"4h"` teniendo cuidado de evitar valores como `"10h"`.

-   Crea `medium_flights` para capturar cualquier valor entre cinco y nueve horas. \~

-   Crea `long_flights` para capturar cualquier valor comprendido entre 10 y 16 horas, ambos inclusive.

```{python}
# Create a list of categories
flight_categories = ['Short-haul', 'Medium', 'Long-haul']

# Create short-haul values
short_flights = '^0h|^1h|^2h|^3h|^4h'

# Create medium-haul values
medium_flights = '^5h|^6h|^7h|^8h|^9h'

# Create long-haul values
long_flights = '^10h|^11h|^12h|^13h|^14h|^15h|^16h'

```

Ahora has creado tus categorías y valores, es hora de agregar condicionalmente las categorías en el DataFrame

### Añadir categorías de duración

Ahora que has configurado las categorías y los valores que quieres capturar, ¡es hora de construir una nueva columna para analizar la frecuencia de los vuelos según su duración!

Las variables`flight_categories`, `short_flights`, `medium_flights` y `long_flights` que creaste anteriormente están a tu disposición.

```{python}
import numpy as np
```

#### Instrucciones

-   Crea `conditions`, una lista que contenga subconjuntos de `planes['Duration']` basados en `short_flights`, `medium_flights` y `long_flights`.

-   Crea la columna `"Duration_Category"` llamando a una función que acepte tu lista `conditions` y `flight_categories`, estableciendo los valores no encontrados en `"Extreme duration"`.

-   Crea un gráfico fque muestre el recuento de cada categoría.

```{python}
# Create conditions for values in flight_categories to be created
conditions = [
    (planes['Duration'].str.contains(short_flights)),
    (planes['Duration'].str.contains(medium_flights)),
    (planes['Duration'].str.contains(long_flights))
]

# Apply the conditions list to the flight_categories
planes['Duration_Category'] = np.select(conditions, flight_categories,
                                        default='Extreme duration')

# Plot the counts of each categoryß
sns.countplot(data=planes, x='Duration_Category',
              hue='Duration_Category', legend=False)
plt.show()
```

¡Está claro que la mayoría de los vuelos son de corta distancia.

## Trabajar con datos numéricos

-   El dataset origina de los salarios

```{python}
#| echo: true
#| eval: false
print(salaries.info())
```

![](images/paste-38.png)

-   Salario en Rupias

```{python}
#| echo: true
#| eval: false
print(salaries['Salary_In_Rupees'].head())
```

![](images/paste-39.png)

-   Convirtiendo cadena de caracteres en números

    -   Remover las comas de los valores `Salary_In_Rupees`

    -   Convertir la columna a tipo de dato `float`

    -   Crear una nueva columna convirtiendo la moneda a dólares

```{python}
#| echo: true
#| eval: false
pd.Series.str.replace('Caracter a remover', 'Caracter a reemplazar')
```

```{python}
#| echo: true
#| eval: false
salaries['Salary_In_Rupees'] = salaries['Salary_In_Rupees'].str.replace(',', '')
print(salaries['Salary_In_Rupees'].head())
```

![](images/paste-40.png)

```{python}
#| echo: true
#| eval: false
salaries['Salary_In_Rupees'] = salaries['Salary_In_Rupees'].astype(float) 
```

1 Indian Rupee = 0.012 US Dollars

```{python}
#| echo: true
#| eval: false
salaries['Salary_USD'] = salaries['Salary_In_Rupees'] * 0.012
```

-   Previsualizando la nueva columna

```{python}
#| echo: true
#| eval: false
print(salaries[['Salary_In_Rupees', 'Salary_USD']].head())
```

![](images/paste-41.png)

-   Añadiendo un resumen esrtadístico al DataFrame

```{python}
#| echo: true
#| eval: false
salaries.groupby('Company_Size')['Salary_USD'].mean()
```

![](images/paste-42.png)

Calculo de la desviación estándar de los salarios por experiencia:

![](images/paste-43.png)

```{python}
#| echo: true
#| eval: false
salaries['std_dev'] = salaries.groupby('Experience') \ 
                      ['Salary_USD'].transform(lambda x: x.std())
```

```{python}
#| echo: true
#| eval: false
print(salaries[['Experience', 'std_dev']].value_counts())
```

![](images/paste-44.png)

Repitamos el proceso para otros datos estadísticos:

```{python}
#| echo: true
#| eval: false
salaries['median_by_comp_size'] = salaries.groupby('Company_Size') \
                                  ['Salary_USD'].transform(lambda x: x.median())
```

```{python}
#| echo: true
#| eval: false
print(salaries[['Company_Size', 'median_by_comp_size']].head())
```

![](images/paste-45.png)

### Duración del vuelo

Te gustaría analizar la duración de los vuelos, pero por desgracia, la columna `"Duration"` de DataFrame `planes` contiene actualmente valores de cadena.

Tendrás que limpiar la columna y convertirla al tipo de datos correcto para el análisis.

```{python}
import re

def duration_to_decimal_str(duration_str: str) -> str:
    '''
    Convierte una duración de vuelo de formato '2h 30m' a una cadena en formato decimal en horas, como '2.5h'.
    
    Parámetros:
    -----------
    duration_str : str
        Cadena de texto que representa la duración de un vuelo, como '2h 30m', '45m', '19h', etc.

    Retorna:
    --------
    str
        Cadena con duración expresada en horas decimales, con un solo decimal y el sufijo 'h'. Ej: '2.5h'
    '''
    horas = re.search(r'(\d+)\s*h', duration_str)
    minutos = re.search(r'(\d+)\s*m', duration_str)

    h = int(horas.group(1)) if horas else 0
    m = int(minutos.group(1)) if minutos else 0

    decimal_hours = round(h + m / 60, 1)
    return f'{decimal_hours}h'



planes['Duration'] = planes['Duration'].apply(duration_to_decimal_str)

```

#### Instrucciones

1.  Imprime los cinco primeros valores de la columna `"Duration"`.

```{python}
# Preview the column
print(planes['Duration'].head())
```

2.  Retira `"h"` de la columna

```{python}
# Remove the string character
planes['Duration'] = planes['Duration'].str.replace('h', '')
print(planes['Duration'].head())
```

3.  Convierte la columna al tipo de datos `float`.

```{python}
# Convert to float data type
planes['Duration'] = planes['Duration'].astype(float)
print(planes['Duration'].head())
```

4.  Traza un histograma de los valores de `"Duration"`

```{python}
# Plot a histogram
sns.histplot(data=planes, x='Duration')
plt.show()
```

### Añadir estadísticas descriptivas

Ahora `"Duration"` y `"Price"`contienen valores numéricos en el DataFrame `planes`, y te gustaría calcular para ellos estadísticas de resumen condicionadas a los valores de otras columnas.

#### Instrucciones

1.  Añade una columna a `planes` que contenga la desviación estándar de `"Price"` basada en `"Airline"`.

```{python}
# Price standard deviation by Airline
planes['airline_price_st_dev'] = planes.groupby('Airline')['Price'].transform(lambda x: x.std())
print(planes[['Airline', 'airline_price_st_dev']].value_counts())
```

2.  Calcula la mediana de `"Duration"` en `"Airline"`, almacenándola como una columna llamada `"airline_median_duration"`.

```{python}
# Median Duration by Airline
planes['airline_median_duration'] = planes.groupby('Airline')['Duration'].transform(lambda x: x.median())
print(planes[['Airline', 'airline_median_duration']].value_counts())
```

3.  Encuenta la media `"Price"` por `"Destination"`, guardándola como una columna llamada `"price_destination_mean"`.

```{python}
# Mean Price by Destination
planes['price_destination_mean'] = planes.groupby('Destination')['Price'].transform(lambda x: x.mean())
print(planes[['Destination', 'price_destination_mean']].value_counts())
```

Parece que Jet Airways tiene la mayor desviación estándar en precio, Air India tiene la mayor duración median, y Nueva Delhi, en promedio, es el destiono más caro. Ahora veamos cómo manejar los datos atípicos.

## Gestión de valores atípicos

-   Qué es un outlier?
    -   Es una observación que está muy alejada de otros puntos de datos.
-   Usando estadística descriptiva

```{python}
#| echo: true
#| eval: false
print(salaries['Salary_USD'].describe())
```

![](images/paste-46.png)

-   Usando el rango intercuartil

    -   Rango intercuartil (IQR)

        -   IQR = 75th - 25th percentil

        -   Upper outliers \> 75th percentile + (1.5 \* IQR)

        -   Lower Outliers \< 25th percentile - (1.5 \* IQR)

```{python}
#| echo: true
#| eval: false
sns.boxplot(data=salaries, y='Salaary_USD')
plt.show()
```

![](images/paste-47.png)

-   Identificando Umbrales

```{python}
#| echo: true
#| eval: false
# 75th percentil
seventy_fifth = salaries['Salary_USD'].quantile(0.75)

# 25th percentil
twenty_fifth = salaries['Salary_USD'].quantile(0.25)

# Interquartil range
salaries_iqr = seventy_fifth - twenty_fifth

print(salaries_iqr)

```

![](images/paste-48.png)

```{python}
#| echo: true
#| eval: false
# Upper threshold
upper = seventy_fifth + (1.5 * salaries_iqr)

# Lower threshold
lower = twenty_fifth - (1.5 * salaries_iqr)

print(upper, lower)
```

![](images/paste-49.png)

-   Subdividiendo nuestros datos

```{python}
#| echo: true
#| eval: false
salaries[(salaries['Salary_USD'] < lower) | (salaries['Salary_USD'] > upper)] \
        [['Experience', 'Employee_Location', 'Salary_USD']]
```

![](images/paste-50.png)

-   ¿ Por qué buscar los Outliers?

    -   Los Outliers son valores extremos

        -   Pueden no representar con precisión los datos

    -   Pueden sesgar la media y la desviación estándar

    -   Pruebas de estadística y modelos de machine learning requieren datos que tengan una distribución normal y no esten sesgados.

-   Qué hacer con los Outliers?

    -   Preguntas que nos debemos hacer:

        -   Por qué existen los outliers?

        -   Los valores son precisos?

-   Eliminación de Outliers

```{python}
#| echo: true
#| eval: false
no_outliers = salaries[(salaries['Salar_USD'] > lower) & (salaries['Salary_USD'] < upper)]
```

```{python}
#| echo: true
#| eval: false
print(no_outliers['Salary_USD'].describe())
```

![](images/paste-51.png)

-   Distribución de Salarios

![](images/paste-52.png)