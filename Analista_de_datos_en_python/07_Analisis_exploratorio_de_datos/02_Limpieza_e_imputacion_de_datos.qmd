# Limpieza e imputación de datos

Explorar y analizar datos a menudo significa tratar con valores perdidos, tipos de datos incorrectos y valores atípicos. En este capítulo, aprenderás técnicas para gestionar estos problemas y agilizar tus procesos en EDA.

## Tratar los datos que faltan

-   Por qué un dato faltante es un problema?

    -   Afectan las distribuciones
    -   Los datos de la población son menos repreesntativos
    -   Puede resultar en conclusiones incorrectas

-   Ejemplo datos de profesionales de datos

| Column | Description | Data type |
|--------------------|---------------------------------|-------------------|
| `Working_Year` | Year the data was obtained | Float |
| `Designation` | Job title | String |
| `Experience` | Experience level e.g., `"Mid"`, `"Senior"` | String |
| `Employment_Satus` | Type of employment contract e.g., `"FT"`, `"PT"` | String |
| `Employee_Location` | Country of employment | String |
| `Company_Size` | Labels for company size e.g., `"S"`, `"M"`, `"L"` | String |
| `Remote_Working_Ratio` | Porcentage of time working remotely | Integer |
| `Salary_USD` | Salary in US dollars | Float |

-   Revisando los datos faltantes

```{python}
#| echo: true
#| eval: false
print(salaries.isna().sum())
```

![](images/paste-22.png)

-   Estrategias para el manejo de datos faltantes

    -   Eliminar los datos faltantes

        -   5 % o menos del total de valores

    -   Imputar la media, mediana o la moda

        -   Depende de la distribución y contexto

    -   Imputar por sub-grupos

        -   Diferentes niveles de experiencia tienen diferente mediana en el salario

-   Eliminando valores faltantes

```{python}
#| echo: true
#| eval: false
threshold = len(salaries) * 0.05
print(threhold)
```

![](images/paste-23.png)

```{python}
# | echo: true
# | eval: false
cols_to_drop = salaries.columns[salaries.isna().sum() <= threshold]
print(cols_to_drop)
```

![](images/paste-24.png)

```{python}
#| echo: true
#| eval: false
salaries.dropna(subset=cols_to_drop, inplace=True) # Para actualizar el DataFrame
```

-   Imputando una estadística de resumen

```{python}
#| echo: true
#| eval: false
cols_with_missing_values = salaries.columns[salaries.isna().sum() > 0]
print(cols_with_missing_values)
```

![](images/paste-25.png)

```{python}
#| echo: true
#| eval: false
    for col in cols_with_missing_values[:-1]:
        salaries[col].fillna(salaries[col].mode()[0])
```

-   Revisando los valores faltantes que faltan

```{python}
#| echo: true
#| eval: false
print(salaries.isna().sum())
```

![](images/paste-26.png)

-   Imputando por subgrupo

```{python}
#| echo: true
#| eval: false
salaries_dict = salaries.groupby('Experience')['Salary_USD'].median().to_dict()
print(salaries_dict)
```

![](images/paste-27.png)

```{python}
#| echo: true
#| eval: false
salaries['Salary_USD'] = salaries['Salary_USD'].fillna(salaries['Experience'].map(salaries_dict))
```

![](images/paste-28.png)

### Tratar los datos que faltan

Es importante tratar los datos que faltan antes de empezar el análisis.

Un enfoque consiste en descartar los valores que faltan si representan una pequeña proporción, normalmente el 5 %, de los datos.

Trabajando con un conjunto de datos sobre precios de tiquetes de avión, almacenado como un DataFrame de pandas llamado `planes`, tendrás que contar el número de valores perdidos en todas las columnas, calcular el cinco porciento de todos los valores, utilizar este umbral para eliminar observaciones y comprobar cuántos valores perdidos quedan en el conjunto de datos.

```{python}
import pandas as pd

ruta = './data/planes.csv'
planes = pd.read_csv(ruta)
print(planes.head)
```

#### Instrucciones

1.  Imprime el número de valores perdidos en cada columna del DataFrame

```{python}
# Count the number of missing values in each column
print(planes.isna().sum())
```

2.  Calcula a cuántas observaciones equivale el cinco porciento del DataFrame `planes`

```{python}
# Find the five percent threshold
threshold = len(planes) * 0.05
print(threshold)
```

3.  

-   Crea `cols_to_drop` aplicando una indexación booleana a las columnas del DataFrame con valores perdidos menores o iguales que el umbral.

-   Utiliza este filtro para eliminar los valores que faltan y guardar el DataFrame actualizado.

```{python}
# Create a filter
cols_to_drop = planes.columns[planes.isna().sum() <= threshold]
print(cols_to_drop)

# Drop missing values for columns below the threshold
planes.dropna(subset=cols_to_drop, inplace=True)

print(planes.isna().sum())
```

Al crear un umbral de valores faltantes y usarlo para filtrar columnas, haz logrado eliminar los valores faltantes de todas las columnas excepto `"Additinal_Info"` y `"Price"`.

### Estrategias para datos que faltan

La regla del cinco porciento ha funcionado muy bien en tu conjunto de dato `planes`, ¡eliminando los valores perdidos de nueve de las 11 columnas!

Ahora tienes que decidir qué hacer con las columnas `"Additional_Info"` y `"Price"`, a las que les faltan los valores `300` y `368` respectivamente.

Primero echarás un vistazo a lo que contiene `"Additional_Info"`, y después visualizarás el precio de los billetes de avión de distintas compañías aéreas.

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
```

#### Instrucciones

1.  Imprime los valores y frecuencias de `"Additional_Info"`.

```{python}
# Check the values of the Additional_Info column
print(planes['Additional_Info'].value_counts())
```

2.  Crea un boxplot de `"Price"` frente a `"Airline"`

```{python}
# Create a box plot of Price by Airline
sns.boxplot(data=planes, x='Airline', y='Price',
            hue='Airline', legend=False)

plt.show()
```

3.  **Pregunta**

-   ¿Cómo debes tratar los valores que faltan en `"Additional_Info"` y `"Price"`.?

**Respuestas Posibles**

-   [ ] Elimina la columna `"Additional_Info"` e imputa la media para los valores que faltan de `"Price"`.
-   [ ] Elimina los valores de `"No info"` de `"Additiona_Info"` e imputa la mediana de los valores que faltan de `"Price"`.
-   [ ] Elimina la columna `"Additional_Info"` e imputa la media por `"Airline"` para los valores que falten de `"Price"`.
-   [x] Elimina la columna `"Additional_Info"` e imputa la mediana por `"Airline"` para los valores que falten de `"Price"`.

No necesitamos la columna `"Additional_Info"`, y deberías imputar la mediana de `"Price"` por `"Airline"` para representar los datos con precisión.

### Imputar los precios de los aviones que faltan

!Ahora solo queda una columna con valores perdidos!

Has eliminado la columna `"Additional_Info"` de `planes`, el último paso es imputar los datos que faltan en la columna `"Price"` del conjunto de datos.

Como recordatorio, tú generaste este diagrama de caja, que sugería que imputar el precio medio basándose en el `"Airline"` ¡es un enfoque sólido!

```{python}
# Eliminamos la columna Additional_Info
planes = planes.drop('Additional_Info', axis=1)
planes.columns
```

#### Instrucciones

1.  Agrupa `planes` por aerolínea y calcula el precio medio.

```{python}
# Calculate median plane ticket prices by Airplane
airline_prices = planes.groupby('Airline')['Price'].median()

print(airline_prices)
```

2.  Convierte los precios medios agrupados en un diccionario.

```{python}
# Convert to a dictionary
prices_dict = airline_prices.to_dict()
print(prices_dict)
```

3.  

-   Imputa condicionalmente los valores perdidos de `"Price"` asignando los valores de la columna `"Airline"` en función de `prices_dict`

-   Comprueba si faltan valores

```{python}
# Map the dictionary to missing values of Price by Airline
planes['Price'] = planes['Price'].fillna(planes['Airline'].map(prices_dict))

# Check for missing values
print(planes.isna().sum())
```

Convertiste un DataFrame agrupado a un diccionario y luego lo usaste para llenar condicionalmente los valores faltantes de `"Price"` basándote en `"Airline"`. Ahora vamos a explorar cómo realizar análisis exploratorio en datos categóricos.

## Convertir y analizar datos categóricos

-   Previsualizar los datos

```{python}
#| echo: true
#| eval: false
print(salaries.select_dtypes('object').head())
```

![](images/paste-29.png)

-   Títulos de los trabajos

```{python}
#| echo: true
#| eval: false
print(salaries['Designation'].value_counts())
```

![](images/paste-30.png)

```{python}
# | echo: true
# | eval: false
print(salaries['Designation'].nunique())
```

![](images/paste-31.png)

![](images/paste-32.png)

-   Extrayendo valores desde las categorías

    -   El formato actual de los datos limita la capacidad de generar información.

    -   `pandas.Series.str.contains()`

        -   Busca en una columna una cadena especifica o múltiples cadenas.

```{python}
#| echo: true
#| eval: false
salaries['Designation'].str.contains('Scientist')
```

![](images/paste-33.png)

-   Filtrar filas que contienen una o más frases

    -   Palabras de interes: Machine Learning o AI

```{python}
#| echo: true
#| eval: false
salaries['Designation'].str.contains('Machine Learning|AI')
```

![](images/paste-34.png)

-   Buscar múltiples frases en una cadena de caracteres

    -   Palabras de interes: Cualquiera que inicie con Data

```{python}
# | echo: true
# | eval: false
salaries['Designation'].str.contains('ˆData')
```

![](images/paste-35.png)

Ahora que se tiene una idea de cómo funciona este método, definamos una lista de títulos de trabajo que queremos encontrar:

```{python}
#| echo: true
#| eval: false
job_categories = ['Data Science', 'Data Analytics',
                   'Data Engineering', 'Machine Learning',
                   'Managerial', 'Consultant']
```

Luego necesitamos crear variables que contengan nuestros filtros

```{python}
#| echo: true
#| eval: false
data_science = 'Data Scientist|NLP'
data_analyst = 'Analyst|Analytics'
data_engineer = 'Data Engineer|ETL|Architect|Infrastructure'
ml_engineer = 'Machine Learning|ML|Bid Data|AI'
manager = 'Manager|Head|Director|Lead|Principal|Staff'
consultant = 'Consultant|Freelance'
```

El siguiente paso es crear una lista con nuestro rango de condiciones para el método `str.contains`

```{python}
#| echo: true
#| eval: false
conditions = [
    (salaries['Designation'].str.contains(data_science)),
    (salaries['Designation'].str.contains(data_analyst)),
    (salaries['Designation'].str.contains(data_engineer)),
    (salaries['Designation'].str.contains(ml_engineer)),
    (salaries['Designation'].str.contains(manager)),
    (salaries['Designation'].str.contains(consultant))
]
```

Finalmente, podemos crear nuestra nueva columna `Job_Category` usando la función de selección de Numpy

```{python}
#| echo: true
#| eval: false
salaries['Job_Category'] = np.select(conditions,
                                     job_categories,
                                     default='Other')
```

Al obtener una vista previa de la Designación y nuestra nueva columna Job_Category, podemos verificar los primeros cinco valores.

```{python}
#| echo: true
#| eval: false
print(salaries[['Designation', 'Job_Category']].head())
```

![](images/paste-36.png)

-   Visualización de la frecuencia de la categoría job

```{python}
#| echo: true
#| eval: false
sns.countplot(data=salaries, x='Job_Category')
plt.show()
```

![](images/paste-37.png)

### Encontrar el número de valores únicos

Te gustaría practicar algunas de las habilidades de manipulación y análisis de datos categóricos que acabas de ver. Para ayudarte a identificar qué datos podrían reformatearse para extraer valor, vas a averiguar qué columnas no numéricas del conjunto de datos `planes` tienen un gran número de valores únicos.

#### Instrucciones

- Filtra `planes` para las columnas que sean del tipo datos `"object"`.

- Recorre las columnas del conjunto de datos.

- Añade el iterador de columna a la sentencia print  y, a continucación, llama a la función para que devuelva el número de valores únicos de la columna.

```{python}
# Filter the DataFrame for objects columns
non_numeric = planes.select_dtypes('object')

# Loop through columns
for column in non_numeric.columns:
    # Print the number of unique values
    print(f"Number of unique values in {column} column: {non_numeric[column].nunique()}")
```
Curiosamente, `"Duration"` es actualmente una columna de tipo objeto cuando debería ser una columna numérica, ¡y tiene 362 valores únicos! Vamos a averiguar más sobre esta columna.

## Trabajar con datos numéricos

## Gestión de valores atípicos